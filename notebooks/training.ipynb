{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d44567",
   "metadata": {},
   "source": [
    "# Pangaea Training Notebook\n",
    "\n",
    "This notebook aims to help users train their desired models on whichever datasets they wish, by building a console command from user preferences. \n",
    "\n",
    "## Using this notebook\n",
    "\n",
    "Each section (e.g. \"X Options\") refers to a different facet of using Foundation Models. Tasks, Datasets, Encoders, Decoders, and so on, all have their own section here. Each section is organized into subsections for consistency and readability. Below is a brief explanation of how the subsections function and relate to one another. \n",
    "\n",
    "**Filenames subsection**: \n",
    "\n",
    "This will contain a set of preconfigured code options that the user can choose from. The first cell will run a check in the repository for existing code, and will print out a list of options for the user to pick from. For example, the first section, called Task Options, will print out a list of the various tasks that users can perform with the FMs in this repo. Users will pick from this list to perform the task that they desire. This will hold true for any section in the notebook; if using code from the repo directly, one only needs to change the associated variable (`task` in our Task Options example).  \n",
    "\n",
    "**Parameters subsection**: \n",
    "\n",
    "This section contains contents of .yaml files, which represent the configuration for a certain code behavior. The Dataset Options section, for instance, has a parameters subsection that contains multiple different variables that need to be edited by the user, if they wish to use their own dataset. Each variable in this subsection represents a configurable value -- <span style=\"color: red\">each variable has its own format and other considerations, so be sure to read comments</span> (`# this is a comment`). *If users prefer, they can read the documentation (linked below) and edit .yaml files directly. The parameters subsection is designed to be easy to use, but some users may find the direct configuration of the yaml file more desirable.* \n",
    "\n",
    "**Build config**: \n",
    "\n",
    "At the end of sections that allow for more customization, some code will run to incorporate user preferences with stock preferences. If no stock preferences were chosen (by leaving the associated variable as the empty string, `\"\"`, in the filename section), then the configuration will be built entirely from user preferences. \n",
    "\n",
    "**Final notebook section**: \n",
    "\n",
    "The very bottom of the notebook will run a command-line interface to begin training with the user configuration that was built in this notebook. This will include logging to display progress and any errors that may arise. \n",
    "\n",
    "## Questions?\n",
    "\n",
    "If you have any questions, please read the [documentation](https://nasa-nccs-hpda.github.io/ilab-pangaea-bench/), which includes sections on troubleshooting and individual config file needs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f189fdf2-1c54-4a80-bab0-9f21ff20ff6f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Imports and helper function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a24abf-fc55-412e-897f-ecbde9fc9bed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42d4775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import subprocess\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a9d150-803d-4c77-af65-eaa9b2bc9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_script import build_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4671250",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### get_folder_options\n",
    "This function lists all possible options for the given parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe3d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_options(base_path):\n",
    "    path = os.path.join((\"../configs\"), base_path)\n",
    "    return [\n",
    "        os.path.splitext(fn)[0]\n",
    "        for fn in os.listdir(path)\n",
    "        if \".yaml\" in fn\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0852f74-6158-4a19-8443-06a1f7c02141",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### collect_config_variables\n",
    "Takes the global variables from this notebook and creates a parameters dictionary that will be used to create a config file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58f79ca-805f-4c10-a73f-5b5ce88a15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_config_variables(config_var_names=[]):\n",
    "    \"\"\"\n",
    "    Collect all user-defined configuration variables from the notebook globals.\n",
    "    \"\"\"\n",
    "    # Get all variables from the global namespace\n",
    "    all_vars = globals()\n",
    "    \n",
    "    # Extract only the config variables\n",
    "    config_dict = {}\n",
    "    for var_name in config_var_names:\n",
    "        if var_name in all_vars:  \n",
    "            # Updated our config_dict only if our value is non-negative and truthy (\"\" ignored)\n",
    "            var = all_vars[var_name]\n",
    "            if var and not (isinstance(var, int) and var < 0):\n",
    "                config_dict[var_name] = all_vars[var_name]\n",
    "            del globals()[var_name]\n",
    "        else:\n",
    "            print(f\"Warning: Variable '{var_name}' not found in globals\")\n",
    "    \n",
    "    return config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba748bd",
   "metadata": {},
   "source": [
    "## Defining command options\n",
    "Here is where users will pick from a list of options for training. The first cell in each subsection will generate a list of options, and the second cell will be where users will enter their choice from the list provided. \n",
    "\n",
    "**This is where you need to edit this notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce618f99-e6e0-4f55-96b1-19a50f050189",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Task Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dadc3b-3271-4789-b738-b526b349c0ae",
   "metadata": {},
   "source": [
    "#### Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c4303b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['change_detection', 'knn_probe', 'knn_probe_multi_label', 'linear_classification', 'linear_classification_multi_label', 'regression', 'segmentation']\n"
     ]
    }
   ],
   "source": [
    "task_options = get_folder_options(\"task\")\n",
    "print(task_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e9044bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"regression\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdf7fcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dataset Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c2b8c-6c94-4734-915c-6d7c12b2b8d3",
   "metadata": {},
   "source": [
    "#### Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61212109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spacenet7', 'spacenet7cd', 'xview2', 'aboveshrubschm', 'ai4smallfarms', 'biomassters', 'croptypemapping', 'dynamicen', 'fivebillionpixels', 'fivebillionpixels_cross_sensors', 'hlsburnscars', 'landsatnlcd-Copy1', 'landsatnlcd', 'mados', 'mbigearthnet', 'mbrickkiln', 'mcashew-plantation', 'mchesapeake-landcover', 'meurosat', 'mforestnet', 'mneontree', 'mnz-cattle', 'mpv4ger-seg', 'mpv4ger', 'msa-crop-type', 'mso2sat', 'oceancolor', 'oceancolor_tm', 'oceancolorval', 'opencanopy', 'pastis', 'potsdam', 'sen1floods11']\n"
     ]
    }
   ],
   "source": [
    "# PRINT OPTIONS\n",
    "dataset_options = get_folder_options(\"dataset\")\n",
    "print(dataset_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c772c0eb-d4b5-4a02-a7ee-7bc70bac6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"\"  # Choose from the options listed above, or leave as \"\" to make your own dataset config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37ebdc-bc4f-4d75-ac6c-51150e66d086",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b0b5990-354b-41c9-a944-4a397e8017c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If making your own dataset\n",
    "target_class = \"CustomPangaeaDataset\"\n",
    "_target_ = f\"pangaea.datasets.{target_class}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f9ccc20-0ff8-4de1-a6ff-a0c6f0d8c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS EDIT\n",
    "root_path = \".\"  # Where to gather dataset files from on ADAPT\n",
    "download_url = \"https://fakewebsite.com\"  # Where to download files from (will be downloaded to\n",
    "img_size = 224  # Height and Width of individual dataset images (must be square)\n",
    "\n",
    "# Bands are separated by modality; each modality is a key: value pair in the dictionary\n",
    "bands = {\n",
    "    \"optical\": [f\"B{i}\" for i in range(1, 12)]  # B1 thru B12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebf1a58b-3ac0-4a5b-aac6-5c909c413dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK-DEPENDANT OPTIONS\n",
    "multi_temporal = False  # Whether input data is multi-temporal\n",
    "multi_modal = False  # Whether input data is multimodal\n",
    "num_classes = 1  # For classification/segmentation, change this value to your number of classes\n",
    "classes = [\"regression\"]  # List of class names; only needs changing for classification or segmentation\n",
    "distribution = [0]  # List of probability of encountering certain target values; only used for classification or segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d22bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED FOR STOCK MIN-MAX SCALING PREPROCESSING\n",
    "# As with bands above, these are separated by modality, add more k: v pairs if needed\n",
    "data_mean = {\n",
    "    \"optical\": [0.5] * 13\n",
    "}\n",
    "data_std = {\n",
    "    \"optical\": [0] * 13\n",
    "}\n",
    "data_min = {\n",
    "    \"optical\": [0.0] * 13\n",
    "}\n",
    "data_max = {\n",
    "    \"optical\": [1.0] * 13\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425b8a2-1628-4ad8-92b4-274cff5c2309",
   "metadata": {},
   "source": [
    "#### Build config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa4388-47dc-4e4d-83f0-0a615667e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD STOCK DATASET CONFIG IF DESIRED\n",
    "if (dataset):\n",
    "    with initialize(config_path=\"../configs/dataset\", version_base=None):\n",
    "        ds_cfg = compose(config_name=dataset)\n",
    "else:\n",
    "    ds_cfg = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e14b8a34-5bd2-4287-8a17-965b7ba57534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLLECT USER-DEFINED VARIABLES\n",
    "ds_var_names = [\n",
    "    '_target_', 'root_path', 'download_url', \n",
    "    'img_size', 'distribution', 'bands', 'multi_temporal', \n",
    "    'multi_modal', 'num_classes', 'classes', 'data_mean', \n",
    "    'data_std', 'data_min', 'data_max'\n",
    "]\n",
    "ds_params = collect_config_variables(ds_var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e939aa8f-3dcb-4b0e-a096-08d8577dfeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========BEFORE UPDATES==========\n",
      "params: {'_target_': 'pangaea.datasets.OceanColorDataset', 'root_path': '.', 'download_url': 'https://fakewebsite.com', 'img_size': 224, 'distribution': [0], 'bands': {'optical': ['B1', 'B2', 'B3']}, 'multi_modal': True, 'num_classes': 1, 'classes': ['regression'], 'data_mean': {'optical': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]}, 'data_std': {'optical': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, 'data_min': {'optical': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, 'data_max': {'optical': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}\n",
      "cfg: {}\n",
      "==========AFTER UPDATES==========\n",
      "params: {'_target_': 'pangaea.datasets.OceanColorDataset', 'root_path': '.', 'download_url': 'https://fakewebsite.com', 'img_size': 224, 'distribution': [0], 'bands': {'optical': ['B1', 'B2', 'B3']}, 'multi_modal': True, 'num_classes': 1, 'classes': ['regression'], 'data_mean': {'optical': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]}, 'data_std': {'optical': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, 'data_min': {'optical': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, 'data_max': {'optical': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}\n",
      "cfg: {}\n",
      "Config saved to oceancolordataset.yaml\n"
     ]
    }
   ],
   "source": [
    "# COMBINE STOCK AND USER-DEFINED INTO ONE CONFIG DICT\n",
    "ds_cfg, ds_cfg_filename = build_config(\"dataset\", ds_params, ds_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a678eca",
   "metadata": {},
   "source": [
    "### Encoder options\n",
    "\n",
    "**Note**: encoders have very different architectures from one another. This means that the config files may look quite different from one to the other, so we have included the absolute bare minimum to editing the encoder file. Many other values are left as default values for existing encoders, and if making your own it's assumed you will know how to edit those parameters on your own (outside of this notebook). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea549363",
   "metadata": {},
   "source": [
    "#### Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3340444b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prithvi', 'terramind_large', 'unet_encoder', 'unet_encoder_mi', 'vit', 'vit_mi', 'vit_scratch', 'croma_joint', 'croma_optical', 'croma_sar', 'dofa', 'gfmswin', 'remoteclip', 'resnet50_pretrained', 'resnet50_scratch', 'satlasnet_mi', 'satlasnet_si', 'scalemae', 'spectralgpt', 'ssl4eo_data2vec', 'ssl4eo_dino', 'ssl4eo_mae_optical', 'ssl4eo_mae_sar', 'ssl4eo_moco']\n"
     ]
    }
   ],
   "source": [
    "encoder_options = get_folder_options(\"encoder\")\n",
    "print(encoder_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8328e787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE YOUR ENCODER HERE FROM THE LIST ABOVE\n",
    "encoder = \"prithvi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c73fc8f8-7ffe-476c-9a8a-2e0bc2977ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD STOCK ENCODER CONFIG\n",
    "if (encoder):\n",
    "    with initialize(config_path=\"../configs/encoder\", version_base=None):\n",
    "        enc_cfg = compose(config_name=encoder)\n",
    "else:\n",
    "    enc_cfg = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87fe40c-ac3b-4b29-b9c6-ec3cd62b8886",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "\n",
    "<span style=\"color: red\">Note: these are not exahaustive parameters needed to create a custom encoder. A python file must be created in the `pangaea/encoders` directory, as well as some more specific .yaml parameters. Check the [documentation](https://nasa-nccs-hpda.github.io/ilab-pangaea-bench/) and see some other encoder configuration files for examples.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed95e845-5e62-43e5-b7fb-5e728b1bc517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF MAKING A CUSTOM ENCODER\n",
    "target_py_filename = \"\"  # .py filename of encoder you've written\n",
    "target_class = \"\"  # Name of python class in the .py file above\n",
    "weights_filename = \"\"  # Filename of weights to load\n",
    "download_url = \"https://fakewebsite.com\"  # URL to fetch weights from (e.g. huggingface)\n",
    "output_layers = [3, 5, 7, 11]\n",
    "output_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1516bb76-bc3c-456e-9e2c-a0d1bb3a6185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from dataset, no need to edit\n",
    "input_size = ds_cfg[\"img_size\"] \n",
    "input_bands = ds_cfg[\"bands\"]\n",
    "\n",
    "# NO NEED TO EDIT\n",
    "# Reformats user input to match config formatting, if non-empty string provided\n",
    "if target_py_filename and target_class:\n",
    "    _target_ = f\"pangaea.encoders.{target_py_filename}.{target_class}\" \n",
    "else:\n",
    "    _target = \"\"\n",
    "if weights_filename:\n",
    "    encoder_weights = f\"./pretrained_models/{weights_filename}\" \n",
    "else:\n",
    "    encoder_weights = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd886f34-bc4e-4e89-b45b-2df0c00745fc",
   "metadata": {},
   "source": [
    "#### Build config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4e98345-3d14-4e2a-9e6e-c1b92363537e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Variable '_target_' not found in globals\n",
      "Warning: Variable 'depths' not found in globals\n",
      "Warning: Variable 'num_heads' not found in globals\n",
      "Warning: Variable 'output_dims' not found in globals\n"
     ]
    }
   ],
   "source": [
    "enc_var_names = [\n",
    "    '_target_', 'encoder_weights', 'download_url',\n",
    "    'output_layers', 'output_dim'\n",
    "]\n",
    "enc_params = collect_config_variables(enc_var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2ea3ee7-bfe6-4ebe-8136-a8fbe89ae81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========BEFORE UPDATES==========\n",
      "params: {'download_url': 'https://fakewebsite.com', 'embed_dim': 128, 'patch_size': 16, 'mlp_ratio': 4, 'output_layers': [3, 5, 7, 11]}\n",
      "cfg: {'_target_': 'pangaea.encoders.prithvi_encoder.Prithvi_Encoder', 'encoder_weights': './pretrained_models/Prithvi_EO_V2_300M.pt', 'download_url': 'https://huggingface.co/ibm-nasa-geospatial/Prithvi-EO-2.0-300M/resolve/main/Prithvi_EO_V2_300M.pt', 'embed_dim': 768, 'input_size': 224, 'in_chans': 6, 'patch_size': 16, 'num_heads': 12, 'depth': 12, 'mlp_ratio': 4, 'tubelet_size': 1, 'num_frames': '${dataset.multi_temporal}', 'input_bands': {'optical': ['B2', 'B3', 'B4', 'B8A', 'B11', 'B12']}, 'output_layers': [3, 5, 7, 11], 'output_dim': 768}\n",
      "==========AFTER UPDATES==========\n",
      "params: {'download_url': 'https://fakewebsite.com', 'embed_dim': 128, 'patch_size': 16, 'mlp_ratio': 4, 'output_layers': [3, 5, 7, 11]}\n",
      "cfg: {'_target_': 'pangaea.encoders.prithvi_encoder.Prithvi_Encoder', 'encoder_weights': './pretrained_models/Prithvi_EO_V2_300M.pt', 'download_url': 'https://huggingface.co/ibm-nasa-geospatial/Prithvi-EO-2.0-300M/resolve/main/Prithvi_EO_V2_300M.pt', 'embed_dim': 768, 'input_size': 224, 'in_chans': 6, 'patch_size': 16, 'num_heads': 12, 'depth': 12, 'mlp_ratio': 4, 'tubelet_size': 1, 'num_frames': '${dataset.multi_temporal}', 'input_bands': {'optical': ['B2', 'B3', 'B4', 'B8A', 'B11', 'B12']}, 'output_layers': [3, 5, 7, 11], 'output_dim': 768}\n",
      "Config saved to prithvi_encoder.yaml\n"
     ]
    }
   ],
   "source": [
    "enc_cfg, enc_cfg_filename = build_config(\"encoder\", enc_params, enc_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f132768",
   "metadata": {},
   "source": [
    "### Decoder options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a9af05c-ad4e-45fa-9085-aee5d48c3b88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f978fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_options = get_folder_options(\"decoders\")\n",
    "print(decoder_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46787161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE YOUR DECODER HERE FROM THE LIST ABOVE\n",
    "decoder = \"Reg Upernet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c178e2",
   "metadata": {},
   "source": [
    "### Training and task options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e5892",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_options = get_folder_options(\"preprocessing\")\n",
    "print(preprocessing_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE YOUR PREPROCESSING HERE FROM THE LIST ABOVE\n",
    "preprocessing = \"reg_default\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43fbdfd",
   "metadata": {},
   "source": [
    "#### Loss function\n",
    "Also known as a \"criterion\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39df60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_options = get_folder_options(\"criterion\")\n",
    "print(loss_fn_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c795db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE YOUR LOSS FUNCTION HERE FROM THE LIST ABOVE\n",
    "loss_fn = \"reg_default\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac4c3c2",
   "metadata": {},
   "source": [
    "### GPU Acceleration Options\n",
    "You do not need to edit this section unless you are an advanced user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnodes = 1\n",
    "nproc_per_node = 1\n",
    "script_path = \"../pangaea/run.py\"\n",
    "config_name = \"train\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e35632",
   "metadata": {},
   "source": [
    "## Building the command\n",
    "Do NOT edit anything in this section, or the training command won't execute properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f1738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the command\n",
    "command = [\n",
    "    \"torchrun\",\n",
    "    f\"--nnodes={nnodes}\",\n",
    "    f\"--nproc_per_node={nproc_per_node}\",\n",
    "    script_path,\n",
    "    f\"--config-name={config_name}\",\n",
    "    f\"dataset={dataset}\",\n",
    "    f\"encoder={encoder}\",\n",
    "    f\"decoder={decoder}\",\n",
    "    f\"preprocessing={preprocessing}\",\n",
    "    f\"criterion={loss_fn}\",\n",
    "    f\"task={task}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36645b50",
   "metadata": {},
   "source": [
    "## Running the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = subprocess.run(command, \n",
    "                          capture_output=True, \n",
    "                          text=True, \n",
    "                          check=True)\n",
    "    print(\"Command executed successfully!\")\n",
    "    print(\"STDOUT:\", result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Command failed with return code {e.returncode}\")\n",
    "    print(\"STDERR:\", e.stderr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pangaea-bench]",
   "language": "python",
   "name": "conda-env-.conda-pangaea-bench-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
