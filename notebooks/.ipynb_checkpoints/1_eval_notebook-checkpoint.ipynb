{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d5bc6d-2166-464e-9614-b4d4dd93e214",
   "metadata": {},
   "source": [
    "# PANGAEA Model Testing Notebook\n",
    "\n",
    "Use this notebook to evaluate a Pangaea model. To modify the behavior of this notebook, you can modify the corresponding .yaml file (found under ilab-pangaea-bench/configs), as well as the cells of the notebook. See the \"global variables\" section for some easily editable variables. \n",
    "\n",
    "## Building the environment\n",
    "\n",
    "1) Find the `environment.yml` file in the repo, and executing the command: `conda env create -f environment.yml`. Make sure you are in the ilab-pangaea-repo directory that you've cloned!\n",
    "2) In the jupyterhub session, click on the top right area that says `Python [...]`, and select `conda env: conda-pangaea-bench`.\n",
    "3) You can now run the notebook as needed!\n",
    "\n",
    "## Before you run\n",
    "This notebook is designed to be run on a model that was trained using this repo, either using the training notebook or the CLI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f9727-e23f-4da7-9b4f-21b3c491a17a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import python packages, create and configure local directories, configure GPU acceleration, build logger, and set some global variables. \n",
    "\n",
    "**Note: if you want to change the functionality of this notebook, the Global Variables subsection is a good place to start.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea70f15-7d62-4a9d-8bdf-e2c6d04d6b3c",
   "metadata": {},
   "source": [
    "### Imports and clone repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c6c16f6-c33e-40ca-8876-3502d8a3434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from hydra.utils import instantiate\n",
    "from hydra import initialize, compose\n",
    "from hydra import initialize_config_dir\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torchmetrics.classification import JaccardIndex\n",
    "\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import pandas as pd\n",
    "import sys\n",
    "import subprocess\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b74598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -angaea (/panfs/ccds02/nobackup/people/ajkerr1/.conda/envs/pangaea-bench/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angaea (/panfs/ccds02/nobackup/people/ajkerr1/.conda/envs/pangaea-bench/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  DEPRECATION: Legacy editable install of pangaea==1.0.0 from file:///panfs/ccds02/nobackup/people/ajkerr1/EO_FM/ilab-pangaea-bench/notebooks/ilab-pangaea-bench (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angaea (/panfs/ccds02/nobackup/people/ajkerr1/.conda/envs/pangaea-bench/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "repo_name = \"ilab-pangaea-bench\"\n",
    "if not os.path.exists(repo_name):\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/nasa-nccs-hpda/ilab-pangaea-bench.git\"], \n",
    "                   check=True, stdout=subprocess.DEVNULL)\n",
    "else:\n",
    "    subprocess.run([\"git\", \"-C\", repo_name, \"pull\"], check=True, stdout=subprocess.DEVNULL)\n",
    "\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \"./ilab-pangaea-bench\"], \n",
    "               check=True, stdout=subprocess.DEVNULL)\n",
    "sys.path.append(\"ilab-pangaea-bench\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "434ad3ea-9025-4e3d-9bdd-ff1e58550825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangaea.decoders.base import Decoder\n",
    "from pangaea.encoders.base import Encoder\n",
    "from pangaea.utils.logger import init_logger\n",
    "from pangaea.datasets.base import GeoFMDataset\n",
    "from pangaea.utils.collate_fn import get_collate_fn\n",
    "from pangaea.utils.eval_utils import (config_cuda, load_apply_ckpt, test_loop,\n",
    "                                      plot_results_heatmap, plot_results_scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25436b46-fdf8-489b-99d9-82729fe06804",
   "metadata": {},
   "source": [
    "### Create and configure directories\n",
    "These dictate where our outputs (logs, plots, etc) will be directed. A folder with the current date and time will be created.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55fe7d78-6b06-4b11-aa10-3b7a0e13420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_experiment_dirs(datetime_str, base_dir=\".\"):\n",
    "    exp_dir = Path(base_dir) / datetime_str\n",
    "    exp_dir.mkdir(exist_ok=True)\n",
    "    logger_path = exp_dir / \"test.log\"\n",
    "\n",
    "    return exp_dir, logger_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "638a676f-dae5-4cc0-8472-5b139b1019c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_str = datetime.datetime.now().strftime(\"%Y-%m-%d-%H:%M\")\n",
    "exp_dir, logger_path = make_experiment_dirs(datetime_str, \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02af3c5-f417-497a-bcc4-c9759f402a62",
   "metadata": {},
   "source": [
    "### Global Variables\n",
    "These will affect the rest of the notebook, change them for your individual task. For example, if you wish to create your own .yaml file to run this notebook, change the `config_name` variable below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "852b1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to create the working directory for this notebook\n",
    "working_dir = exp_dir  # Default is to use exp_dir for everything\n",
    "\n",
    "# Plotting path information\n",
    "heatmap_plot_filename = f\"heatmap\"\n",
    "scatter_plot_filename = f\"scatter\"\n",
    "\n",
    "# How much info the logger will display; 0 means no logging, 1 means minimal logging, 2 means extra logging detail\n",
    "logger_verbosity = 0\n",
    "\n",
    "# This creates a directory where we will load our trained model checkpoint\n",
    "ckpt_path = \"/explore/nobackup/people/mfrost2/lscratch/EO_FM/ex_train_dir\"\n",
    "experiment_dir = \"20250818_095532_c0e748_terramind_landsat_large_seg_upernet_landsatnlcd_7band\"\n",
    "ckpt_dir = Path(ckpt_path, experiment_dir)\n",
    "\n",
    "# This can be left as the empty string, \"\", if your test data is in the same directory as training data\n",
    "# Otherwise, this notebook will try to evaluate using the same data used to train the model checkpoint\n",
    "test_data_dir = (\"/explore/nobackup/people/mfrost2/lscratch\"\n",
    "                 \"/EO_FM/data/Landsat_NLCD_data_agg5/test\")\n",
    "\n",
    "# Where we will load our hydra config from\n",
    "config_path = str(ckpt_dir / \"configs\" / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d754db4-1c17-48ac-bd22-d8433b07b1bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Configure Hydra\n",
    "This allows us to run a test using the .yaml framework from Pangaea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22e4babb-7454-41a8-bab6-893952008040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Init Hydra from config\n",
    "with initialize_config_dir(config_dir=config_path, version_base=None):\n",
    "    cfg = OmegaConf.load(config_path)\n",
    "\n",
    "print(\"Config loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd3349-a445-4fc4-bba4-b181d063515a",
   "metadata": {},
   "source": [
    "### Configure CUDA for GPU acceleration\n",
    "We need this to run our notebook on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a56c934e-a9f9-4a11-a973-2cb87a3b387d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single GPU training detected, skipping distributed init.\n"
     ]
    }
   ],
   "source": [
    "device, local_rank, world_size = config_cuda(cfg, backend=\"nccl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e6893a-d93e-439d-92df-8a4baee39d5d",
   "metadata": {},
   "source": [
    "### Build logger\n",
    "\n",
    "This provides some debugging information on various processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01aac4c7-b86c-4024-9022-a28e9f03daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logger(cfg, logger_path, exp_dir, device, rank=local_rank):\n",
    "    logger = init_logger(logger_path, rank=rank)\n",
    "    if (logger_verbosity > 0):\n",
    "        logger.info(\"============ Initialized logger ============\")\n",
    "        if (logger_verbosity > 1):\n",
    "            logger.info(pprint.pformat(OmegaConf.to_container(cfg), compact=True).strip(\"{}\"))\n",
    "        logger.info(\"The experiment is stored in %s\\n\" % exp_dir)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffa65df8-6387-45bc-a923-e3639c9c927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = build_logger(cfg, logger_path, exp_dir, device, local_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5b3a0-7ce0-4b87-b8c0-709823a90697",
   "metadata": {},
   "source": [
    "### Editing config to use test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25791437-3b6d-47a6-8c9e-d5345ad1b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg[\"dataset\"][\"root_path\"] = test_data_dir\n",
    "cfg.train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd990ec0-523d-41fd-bfb6-57e6e317dc8f",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56016791-6b01-4e89-b436-da17479add85",
   "metadata": {},
   "source": [
    "### Initialize encoder/decoder before loading checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c080ff50-d9fc-46fa-af56-f0f99d71227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(cfg, logger):\n",
    "    encoder: Encoder = instantiate(cfg.encoder)\n",
    "    encoder.load_encoder_weights(logger)\n",
    "    logger.info(f\"Built {encoder.model_name}, using weights from: {cfg.encoder.download_url}\")\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(cfg, encoder, device, logger):\n",
    "    decoder: Decoder = instantiate(\n",
    "        cfg.decoder,\n",
    "        encoder=encoder,\n",
    "    )\n",
    "    decoder.to(device)\n",
    "    decoder_name = cfg.decoder._target_.split(\".\")[-1]\n",
    "    logger.info(f\"Built {decoder_name} decoder.\")\n",
    "\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49db8e70-11ba-43aa-9cdd-c2f86628a470",
   "metadata": {},
   "outputs": [
    {
     "ename": "InstantiationException",
     "evalue": "Error locating target 'pangaea.encoders.terramind_landsat_encoder.terramind_v1_large', set env var HYDRA_FULL_ERROR=1 to see chained exception.\nfull_key: encoder",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/pangaea-bench/lib/python3.10/site-packages/hydra/_internal/utils.py:644\u001b[0m, in \u001b[0;36m_locate\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc_attr:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pangaea.encoders' has no attribute 'terramind_landsat_encoder'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/pangaea-bench/lib/python3.10/site-packages/hydra/_internal/utils.py:650\u001b[0m, in \u001b[0;36m_locate\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pangaea-bench/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pangaea.encoders.terramind_landsat_encoder'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/pangaea-bench/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:134\u001b[0m, in \u001b[0;36m_resolve_target\u001b[0;34m(target, full_key)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 134\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[43m_locate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/pangaea-bench/lib/python3.10/site-packages/hydra/_internal/utils.py:653\u001b[0m, in \u001b[0;36m_locate\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc_import:\n\u001b[0;32m--> 653\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    654\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(exc_import)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAre you sure that \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is importable from module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent_dotpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    656\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc_import\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc_import:\n",
      "\u001b[0;31mImportError\u001b[0m: Error loading 'pangaea.encoders.terramind_landsat_encoder.terramind_v1_large':\nModuleNotFoundError(\"No module named 'pangaea.encoders.terramind_landsat_encoder'\")\nAre you sure that 'terramind_landsat_encoder' is importable from module 'pangaea.encoders'?",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Model operations in Pangaea require a logger\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Pangaea wraps encoder and decoder into one Decoder type\u001b[39;00m\n\u001b[1;32m      4\u001b[0m encoder_decoder \u001b[38;5;241m=\u001b[39m build_decoder(cfg, encoder, device, logger)\n",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m, in \u001b[0;36mbuild_encoder\u001b[0;34m(cfg, logger)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_encoder\u001b[39m(cfg, logger):\n\u001b[0;32m----> 2\u001b[0m     encoder: Encoder \u001b[38;5;241m=\u001b[39m \u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     encoder\u001b[38;5;241m.\u001b[39mload_encoder_weights(logger)\n\u001b[1;32m      4\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoder\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, using weights from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mdownload_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/pangaea-bench/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     _convert_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mCONVERT, ConvertMode\u001b[38;5;241m.\u001b[39mNONE)\n\u001b[1;32m    224\u001b[0m     _partial_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mPARTIAL, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_recursive_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_convert_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_partial_\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m OmegaConf\u001b[38;5;241m.\u001b[39mis_list(config):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     config_copy \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[0;32m~/.conda/envs/pangaea-bench/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:333\u001b[0m, in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[1;32m    331\u001b[0m exclude_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_target_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_convert_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_recursive_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_partial_\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_target(node):\n\u001b[0;32m--> 333\u001b[0m     _target_ \u001b[38;5;241m=\u001b[39m \u001b[43m_resolve_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_Keys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTARGET\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    335\u001b[0m     is_partial \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_partial_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m partial\n",
      "File \u001b[0;32m~/.conda/envs/pangaea-bench/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:139\u001b[0m, in \u001b[0;36m_resolve_target\u001b[0;34m(target, full_key)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m full_key:\n\u001b[1;32m    138\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mfull_key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InstantiationException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(target):\n\u001b[1;32m    141\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a callable target, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(target)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mInstantiationException\u001b[0m: Error locating target 'pangaea.encoders.terramind_landsat_encoder.terramind_v1_large', set env var HYDRA_FULL_ERROR=1 to see chained exception.\nfull_key: encoder"
     ]
    }
   ],
   "source": [
    "# Model operations in Pangaea require a logger\n",
    "encoder = build_encoder(cfg, logger)\n",
    "# Pangaea wraps encoder and decoder into one Decoder type\n",
    "encoder_decoder = build_decoder(cfg, encoder, device, logger)\n",
    "\n",
    "# Final model is built using distributed GPU resources if we have more than 1 GPU\n",
    "if (world_size > 1):\n",
    "    model = DistributedDataParallel(\n",
    "        encoder_decoder,\n",
    "        device_ids=[local_rank],\n",
    "        output_device=local_rank,\n",
    "        find_unused_parameters=cfg.finetune,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1dbca-f87e-4f60-b55e-728694902eba",
   "metadata": {},
   "source": [
    "### Load model checkpoint from path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f8add-b848-47a6-b0cb-aef9e9dbd906",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_apply_ckpt(ckpt_dir, device, encoder_decoder, logger, logger_verbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eebeff-647b-4b35-b430-b908c6aba3d4",
   "metadata": {},
   "source": [
    "## Load test data, run through model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c81bb-d2ce-4f84-ad44-5e65a2575c2e",
   "metadata": {},
   "source": [
    "### Get Dataloader\n",
    "From our config file, we can build a dataset which is then served in batches by the PyTorch DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9730e-4b87-47c8-88e3-e56dd02db76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(cfg, encoder, logger):\n",
    "    # Preprocessor is required by dataset class\n",
    "    test_preprocessor = instantiate(\n",
    "        cfg.preprocessing.test,\n",
    "        dataset_cfg=cfg.dataset,\n",
    "        encoder_cfg=cfg.encoder,\n",
    "        _recursive_=False,\n",
    "    )\n",
    "\n",
    "    # Create dataset\n",
    "    raw_test_dataset = instantiate(cfg.dataset, split=\"test\")\n",
    "    test_dataset = GeoFMDataset(raw_test_dataset, test_preprocessor)\n",
    "\n",
    "    # Create batches by modality using collate function\n",
    "    modalities = list(encoder.input_bands.keys())\n",
    "    collate_fn = get_collate_fn(modalities)\n",
    "\n",
    "    # Dataloader from dataset\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,  # Change this to a larger size if desired\n",
    "        num_workers=4,  # Change this to a larger number if desired\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    if (logger_verbosity > 1):\n",
    "        logger.info(f\"Built dataloader from dataset: {cfg.dataset.dataset_name}\")\n",
    "        logger.info(f\"Dataset gathered files from: {cfg.dataset.root_path}\")\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb266c-66cb-4d0f-a87e-0171eba443b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_dataloader(cfg, encoder, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba74c9-c54c-4df7-af8c-1887c40fc2c4",
   "metadata": {},
   "source": [
    "### Perform forward pass of model on test dataset\n",
    "Using the test dataloader, we can get model predictions on test inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95048d1a-6b4c-4d9b-9c15-6f2dd5a086a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info(\"Beginning test loop...\")\n",
    "test_dict = test_loop(cfg, model, device, test_loader, logger)\n",
    "logger.info(\"Testing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9283f0-f8d0-4af8-9196-6ad95a16b9c4",
   "metadata": {},
   "source": [
    "## Visualize model performance on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6745765-bd62-4860-80a2-7502b370b815",
   "metadata": {},
   "source": [
    "### Plot targets vs predictions heatmap\n",
    "This plots the first 5 targets and predictions alongside one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7aa30f-8421-4479-8896-50c44a066275",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Creating heatmap and saving to png...\")\n",
    "\n",
    "plot_results_heatmap(\n",
    "    targets=test_dict[\"targets\"],\n",
    "    preds=test_dict[\"preds\"],\n",
    "    save_dir=working_dir,\n",
    "    png_prefix=heatmap_plot_filename,\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abec099-1704-44e4-9d56-b1388b47f6c9",
   "metadata": {},
   "source": [
    "### Create scatter plot\n",
    "This plot visualizes all prediction and target data points based on their closeness. The closer they are to the middle, the more similar they are (and the better the model is performing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd5146-2197-47e1-b528-936a5f66bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Creating scatter plot and saving to png...\")\n",
    "\n",
    "fig, val_df = plot_results_scatter(\n",
    "    targets=test_dict[\"targets\"],\n",
    "    predictions=test_dict[\"preds\"],\n",
    "    save_dir=working_dir,\n",
    "    png_prefix=scatter_plot_filename\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pangaea-bench]",
   "language": "python",
   "name": "conda-env-.conda-pangaea-bench-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
