{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d5bc6d-2166-464e-9614-b4d4dd93e214",
   "metadata": {},
   "source": [
    "# PANGAEA Model Testing Notebook\n",
    "\n",
    "Use this notebook to evaluate a Pangaea model. To modify the behavior of this notebook, you can modify the corresponding .yaml file (found under ilab-pangaea-bench/configs), as well as the cells of the notebook. See the \"global variables\" section for some easily editable variables. \n",
    "\n",
    "## Building the environment\n",
    "\n",
    "1) Find the `environment.yml` file in the repo, and executing the command: `conda env create -f environment.yml`. Make sure you are in the ilab-pangaea-repo directory that you've cloned!\n",
    "2) In the jupyterhub session, click on the top right area that says `Python [...]`, and select `conda env: conda-pangaea-bench`.\n",
    "3) You can now run the notebook as needed!\n",
    "\n",
    "## Before you run\n",
    "This notebook is designed to be run on a model that was trained using this repo, either using the training notebook or the CLI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f9727-e23f-4da7-9b4f-21b3c491a17a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup\n",
    "\n",
    "Import python packages, create and configure local directories, configure GPU acceleration, build logger, and set some global variables. \n",
    "\n",
    "**Note: if you want to change the functionality of this notebook, the Global Variables subsection is a good place to start.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea70f15-7d62-4a9d-8bdf-e2c6d04d6b3c",
   "metadata": {},
   "source": [
    "### Imports and clone repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c6c16f6-c33e-40ca-8876-3502d8a3434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from hydra.utils import instantiate\n",
    "from hydra import initialize, compose\n",
    "from hydra import initialize_config_dir\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torchmetrics.classification import JaccardIndex\n",
    "\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import pandas as pd\n",
    "import sys\n",
    "import subprocess\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6b75253-b6a0-4d2f-b7a8-87253cf83297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install albumentations\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"albumentations\"], \n",
    "                     stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b74598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/nasa-nccs-hpda/ilab-pangaea-bench\n",
      "   6b8a01e..55d02e6  main       -> origin/main\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "repo_name = \"ilab-pangaea-bench\"\n",
    "if not os.path.exists(repo_name):\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/nasa-nccs-hpda/ilab-pangaea-bench.git\"], \n",
    "                   check=True, stdout=subprocess.DEVNULL)\n",
    "else:\n",
    "    subprocess.run([\"git\", \"-C\", repo_name, \"pull\"], check=True, stdout=subprocess.DEVNULL)\n",
    "sys.path.append(\"ilab-pangaea-bench\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434ad3ea-9025-4e3d-9bdd-ff1e58550825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangaea.decoders.base import Decoder\n",
    "from pangaea.encoders.base import Encoder\n",
    "from pangaea.utils.logger import init_logger\n",
    "from pangaea.datasets.base import GeoFMDataset\n",
    "from pangaea.utils.collate_fn import get_collate_fn\n",
    "from pangaea.utils.eval_utils import (config_cuda, load_apply_ckpt, test_loop,\n",
    "                                      plot_results_heatmap, plot_results_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25436b46-fdf8-489b-99d9-82729fe06804",
   "metadata": {},
   "source": [
    "### Create and configure directories\n",
    "These dictate where our outputs (logs, plots, etc) will be directed. A folder with the current date and time will be created.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55fe7d78-6b06-4b11-aa10-3b7a0e13420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_experiment_dirs(datetime_str, base_dir=\".\"):\n",
    "    exp_dir = Path(base_dir) / datetime_str\n",
    "    exp_dir.mkdir(exist_ok=True)\n",
    "    logger_path = exp_dir / \"test.log\"\n",
    "\n",
    "    return exp_dir, logger_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "638a676f-dae5-4cc0-8472-5b139b1019c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_str = datetime.datetime.now().strftime(\"%Y-%m-%d-%H:%M\")\n",
    "exp_dir, logger_path = make_experiment_dirs(datetime_str, \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02af3c5-f417-497a-bcc4-c9759f402a62",
   "metadata": {},
   "source": [
    "### Global Variables\n",
    "These will affect the rest of the notebook, change them for your individual task. For example, if you wish to create your own .yaml file to run this notebook, change the `config_name` variable below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "852b1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to create the working directory for this notebook\n",
    "working_dir = exp_dir  # Default is to use exp_dir for everything\n",
    "\n",
    "# Plotting path information\n",
    "heatmap_plot_filename = f\"heatmap\"\n",
    "second_plot_filename = f\"plot_2\"\n",
    "\n",
    "# How much info the logger will display; 0 means no logging, 1 means minimal logging, 2 means extra logging detail\n",
    "logger_verbosity = 0\n",
    "\n",
    "# This creates a directory where we will load our trained model checkpoint\n",
    "ckpt_path = \"/explore/nobackup/people/ajkerr1/EO_FM/ex_train_dir\"\n",
    "experiment_dir = \"20250820_135320_c07963_dofa_landsat_seg_upernet_landsatnlcd_7band\"\n",
    "ckpt_dir = Path(ckpt_path, experiment_dir)\n",
    "\n",
    "# This can be left as the empty string, \"\", if your test data is in the same directory as training data\n",
    "# Otherwise, this notebook will try to evaluate using the same data used to train the model checkpoint\n",
    "test_data_dir = (\"/explore/nobackup/people/mfrost2/lscratch\"\n",
    "                 \"/EO_FM/data/Landsat_NLCD_data_agg5/test\")\n",
    "\n",
    "# Where we will load our hydra config from\n",
    "config_path = str(ckpt_dir / \"configs\" / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d754db4-1c17-48ac-bd22-d8433b07b1bc",
   "metadata": {},
   "source": [
    "### Configure Hydra\n",
    "This allows us to run a test using the .yaml framework from Pangaea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22e4babb-7454-41a8-bab6-893952008040",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Init Hydra from config\n",
    "with initialize_config_dir(config_dir=config_path, version_base=None):\n",
    "    cfg = OmegaConf.load(config_path)\n",
    "\n",
    "print(\"Config loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ccd7a6-6c19-4993-a81e-473d814cfffa",
   "metadata": {},
   "source": [
    "#### Editing config to use test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25791437-3b6d-47a6-8c9e-d5345ad1b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg[\"dataset\"][\"root_path\"] = test_data_dir\n",
    "cfg.train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd3349-a445-4fc4-bba4-b181d063515a",
   "metadata": {},
   "source": [
    "### Configure CUDA for GPU acceleration\n",
    "We need this to run our notebook on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a56c934e-a9f9-4a11-a973-2cb87a3b387d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single GPU training detected, skipping distributed init.\n"
     ]
    }
   ],
   "source": [
    "device, local_rank, world_size = config_cuda(cfg, backend=\"nccl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e6893a-d93e-439d-92df-8a4baee39d5d",
   "metadata": {},
   "source": [
    "### Build logger\n",
    "\n",
    "This provides some debugging information on various processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01aac4c7-b86c-4024-9022-a28e9f03daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logger(cfg, logger_path, exp_dir, device, rank=local_rank):\n",
    "    logger = init_logger(logger_path, rank=rank)\n",
    "    if (logger_verbosity > 0):\n",
    "        logger.info(\"============ Initialized logger ============\")\n",
    "        if (logger_verbosity > 1):\n",
    "            logger.info(pprint.pformat(OmegaConf.to_container(cfg), compact=True).strip(\"{}\"))\n",
    "        logger.info(\"The experiment is stored in %s\\n\" % exp_dir)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffa65df8-6387-45bc-a923-e3639c9c927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = build_logger(cfg, logger_path, exp_dir, device, local_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd990ec0-523d-41fd-bfb6-57e6e317dc8f",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56016791-6b01-4e89-b436-da17479add85",
   "metadata": {},
   "source": [
    "### Initialize encoder/decoder before loading checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c080ff50-d9fc-46fa-af56-f0f99d71227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(cfg, logger):\n",
    "    encoder: Encoder = instantiate(cfg.encoder)\n",
    "    encoder.load_encoder_weights(logger)\n",
    "    logger.info(f\"Built {encoder.model_name}, using weights from: {cfg.encoder.download_url}\")\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(cfg, encoder, device, logger):\n",
    "    decoder: Decoder = instantiate(\n",
    "        cfg.decoder,\n",
    "        encoder=encoder,\n",
    "    )\n",
    "    decoder.to(device)\n",
    "    decoder_name = cfg.decoder._target_.split(\".\")[-1]\n",
    "    logger.info(f\"Built {decoder_name} decoder.\")\n",
    "\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49db8e70-11ba-43aa-9cdd-c2f86628a470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 09/08/25 15:46:52 - 0:00:09 - Built dofa_encoder, using weights from: https://huggingface.co/XShadow/DOFA/resolve/main/DOFA_ViT_base_e100.pth\n",
      "INFO - 09/08/25 15:46:53 - 0:00:09 - Built SegUPerNet decoder.\n"
     ]
    }
   ],
   "source": [
    "# Model operations in Pangaea require a logger\n",
    "encoder = build_encoder(cfg, logger)\n",
    "# Pangaea wraps encoder and decoder into one Decoder type\n",
    "encoder_decoder = build_decoder(cfg, encoder, device, logger)\n",
    "\n",
    "# Final model is built using distributed GPU resources if we have more than 1 GPU\n",
    "if (world_size > 1):\n",
    "    model = DistributedDataParallel(\n",
    "        encoder_decoder,\n",
    "        device_ids=[local_rank],\n",
    "        output_device=local_rank,\n",
    "        find_unused_parameters=cfg.finetune,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1dbca-f87e-4f60-b55e-728694902eba",
   "metadata": {},
   "source": [
    "### Load model checkpoint from path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "045f8add-b848-47a6-b0cb-aef9e9dbd906",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_apply_ckpt(ckpt_dir, device, encoder_decoder, logger, logger_verbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eebeff-647b-4b35-b430-b908c6aba3d4",
   "metadata": {},
   "source": [
    "## Load test data, run through model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c81bb-d2ce-4f84-ad44-5e65a2575c2e",
   "metadata": {},
   "source": [
    "### Get Dataloader\n",
    "From our config file, we can build a dataset which is then served in batches by the PyTorch DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60c9730e-4b87-47c8-88e3-e56dd02db76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(cfg, encoder, logger):\n",
    "    # Preprocessor is required by dataset class\n",
    "    test_preprocessor = instantiate(\n",
    "        cfg.preprocessing.test,\n",
    "        dataset_cfg=cfg.dataset,\n",
    "        encoder_cfg=cfg.encoder,\n",
    "        _recursive_=False,\n",
    "    )\n",
    "\n",
    "    # Create dataset\n",
    "    raw_test_dataset = instantiate(cfg.dataset, split=\"test\")\n",
    "    test_dataset = GeoFMDataset(raw_test_dataset, test_preprocessor)\n",
    "\n",
    "    # Create batches by modality using collate function\n",
    "    modalities = list(encoder.input_bands.keys())\n",
    "    collate_fn = get_collate_fn(modalities)\n",
    "\n",
    "    # Dataloader from dataset\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,  # Change this to a larger size if desired\n",
    "        num_workers=4,  # Change this to a larger number if desired\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    if (logger_verbosity > 1):\n",
    "        logger.info(f\"Built dataloader from dataset: {cfg.dataset.dataset_name}\")\n",
    "        logger.info(f\"Dataset gathered files from: {cfg.dataset.root_path}\")\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afdb266c-66cb-4d0f-a87e-0171eba443b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1418 paired image-label files in /explore/nobackup/people/mfrost2/lscratch/EO_FM/data/Landsat_NLCD_data_agg5/test/images\n"
     ]
    }
   ],
   "source": [
    "test_loader = get_dataloader(cfg, encoder, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba74c9-c54c-4df7-af8c-1887c40fc2c4",
   "metadata": {},
   "source": [
    "### Perform forward pass of model on test dataset\n",
    "Using the test dataloader, we can get model predictions on test inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95048d1a-6b4c-4d9b-9c15-6f2dd5a086a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 09/08/25 15:46:54 - 0:00:10 - Beginning test loop...\n",
      "Test loop:   0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "logger.info(\"Beginning test loop...\")\n",
    "test_dict = test_loop(cfg, model, device, test_loader, logger)\n",
    "logger.info(\"Testing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9283f0-f8d0-4af8-9196-6ad95a16b9c4",
   "metadata": {},
   "source": [
    "## Visualize model performance on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6745765-bd62-4860-80a2-7502b370b815",
   "metadata": {},
   "source": [
    "### Plot targets vs predictions heatmap\n",
    "This plots the first 5 targets and predictions alongside one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7aa30f-8421-4479-8896-50c44a066275",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Creating heatmap and saving to png...\")\n",
    "\n",
    "plot_results_heatmap(\n",
    "    cfg=cfg,\n",
    "    targets=test_dict[\"targets\"],\n",
    "    preds=test_dict[\"preds\"],\n",
    "    save_dir=working_dir,\n",
    "    png_prefix=heatmap_plot_filename,\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abec099-1704-44e4-9d56-b1388b47f6c9",
   "metadata": {},
   "source": [
    "### Create second eval plot\n",
    "This plot will be different depending on the model task. Classification and regression models will show a scatter plot depicting the closeness of predictions and targets (more symmetrical across the diagonal means better predictions). Segmentation models will display a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd5146-2197-47e1-b528-936a5f66bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Creating eval plot and saving to png...\")\n",
    "\n",
    "fig, val_df = plot_results_variable(\n",
    "    cfg=cfg,\n",
    "    targets=test_dict[\"targets\"],\n",
    "    predictions=test_dict[\"preds\"],\n",
    "    save_dir=working_dir,\n",
    "    png_prefix=second_plot_filename\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pangaea-bench]",
   "language": "python",
   "name": "conda-env-.conda-pangaea-bench-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
