{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d5bc6d-2166-464e-9614-b4d4dd93e214",
   "metadata": {},
   "source": [
    "# PANGAEA Model Testing Notebook\n",
    "\n",
    "Use this notebook to evaluate a Pangaea model. To modify the behavior of this notebook, you can modify the corresponding .yaml file (found under ilab-pangaea-bench/configs), as well as the cells of the notebook. See the \"global variables\" section for some easily editable variables. \n",
    "\n",
    "## Building the environment\n",
    "\n",
    "1) Find the `environment.yml` file in the repo, and executing the command: `conda env create -f environment.yml`. Make sure you are in the ilab-pangaea-repo directory that you've cloned!\n",
    "2) In the jupyterhub session, click on the top right area that says `Python [...]`, and select `conda env: conda-pangaea-bench`.\n",
    "3) You can now run the notebook as needed!\n",
    "\n",
    "## Before you run\n",
    "This notebook is designed to be run on a model that was trained using this repo, either using the training notebook or the CLI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f9727-e23f-4da7-9b4f-21b3c491a17a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import python packages, create and configure local directories, configure GPU acceleration, build logger, and set some global variables. \n",
    "\n",
    "**Note: if you want to change the functionality of this notebook, the Global Variables subsection is a good place to start.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea70f15-7d62-4a9d-8bdf-e2c6d04d6b3c",
   "metadata": {},
   "source": [
    "### Imports and clone repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6c16f6-c33e-40ca-8876-3502d8a3434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from hydra.utils import instantiate\n",
    "from hydra import initialize, compose\n",
    "from hydra import initialize_config_dir\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torchmetrics.classification import JaccardIndex \n",
    "\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import pandas as pd\n",
    "import sys\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b74598",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\"git\", \"clone\", \"https://github.com/nasa-nccs-hpda/ilab-pangaea-bench.git\"], check=True)\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \"./ilab-pangaea-bench\"], check=True)\n",
    "sys.path.append(\"ilab-pangaea-bench\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434ad3ea-9025-4e3d-9bdd-ff1e58550825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangaea.decoders.base import Decoder\n",
    "from pangaea.encoders.base import Encoder\n",
    "from pangaea.utils.logger import init_logger\n",
    "from pangaea.datasets.base import GeoFMDataset\n",
    "from pangaea.utils.collate_fn import get_collate_fn\n",
    "from pangaea.utils.eval_utils import (config_cuda, load_apply_ckpt, eval_loop, \n",
    "                                      plot_results_heatmap, plot_results_scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12fc2a1-e145-427c-a1fb-481c98a9dc63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Import from eval_utils nb (add to repo TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d35682-d102-48a9-82a5-fd03bc16df97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25436b46-fdf8-489b-99d9-82729fe06804",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create and configure directories\n",
    "These dictate where our outputs (logs, plots, etc) will be directed. A folder with the current date and time will be created.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fe7d78-6b06-4b11-aa10-3b7a0e13420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_experiment_dirs(datetime_str, base_dir=\".\"):\n",
    "    exp_dir = Path(base_dir) / datetime_str\n",
    "    exp_dir.mkdir(exist_ok=True)\n",
    "    logger_path = exp_dir / \"test.log\"\n",
    "    \n",
    "    return exp_dir, logger_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a676f-dae5-4cc0-8472-5b139b1019c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_str = datetime.datetime.now().strftime(\"%Y-%m-%d-%H:%M\")\n",
    "exp_dir, logger_path = make_experiment_dirs(datetime_str, \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02af3c5-f417-497a-bcc4-c9759f402a62",
   "metadata": {},
   "source": [
    "### Global Variables\n",
    "These will affect the rest of the notebook, change them for your individual task. For example, if you wish to create your own .yaml file to run this notebook, change the `config_name` variable below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to create the working directory for this notebook\n",
    "working_dir = exp_dir  # Default is to use exp_dir for everything\n",
    "\n",
    "# Plotting path information\n",
    "heatmap_plot_filename = f\"heatmap\"\n",
    "scatter_plot_filename = f\"scatter\"\n",
    "\n",
    "# How much info the logger will display; 0 means no logging, 1 means minimal logging, 2 means extra logging detail\n",
    "logger_verbosity = 0 \n",
    "\n",
    "# This creates a directory where we will load our trained model checkpoint\n",
    "\n",
    "# OCEAN COLOR REGRESSION PRITHVI\n",
    "# trained_model_dir = \"20250806_103631_deb604_prithvi_reg_upernet_oceancolor\"\n",
    "# ckpt_dir_str = f\"/home/ajkerr1/nobackup/EO_FM/testing_dir/model_ckpts/{trained_model_dir}/\"\n",
    "# ckpt_dir = Path(ckpt_dir_str)\n",
    "\n",
    "# LANDSAT NLCD SEGMENTATION DOFA\n",
    "ckpt_path = \"/explore/nobackup/people/mfrost2/lscratch/EO_FM/training_dir/\"\n",
    "ckpt_dir = Path(ckpt_path, \"20250822_151213_a5bd3f_dofa_landsat_seg_upernet_landsatnlcd_7band\")\n",
    "\n",
    "# Where we will load our hydra config from\n",
    "config_path = str(ckpt_dir / \"configs\" / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d754db4-1c17-48ac-bd22-d8433b07b1bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Configure Hydra\n",
    "This allows us to run a test using the .yaml framework from Pangaea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4babb-7454-41a8-bab6-893952008040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Hydra from config\n",
    "with initialize_config_dir(config_dir=config_path, version_base=None):\n",
    "    cfg = OmegaConf.load(config_path)\n",
    "\n",
    "print(\"Config loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd3349-a445-4fc4-bba4-b181d063515a",
   "metadata": {},
   "source": [
    "### Configure CUDA for GPU acceleration\n",
    "We need this to run our notebook on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c934e-a9f9-4a11-a973-2cb87a3b387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device, local_rank, world_size = config_cuda(cfg, backend=\"nccl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e6893a-d93e-439d-92df-8a4baee39d5d",
   "metadata": {},
   "source": [
    "### Build logger\n",
    "\n",
    "This provides some debugging information on various processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aac4c7-b86c-4024-9022-a28e9f03daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logger(cfg, logger_path, exp_dir, device, rank=local_rank):\n",
    "    logger = init_logger(logger_path, rank=rank)\n",
    "    if (logger_verbosity > 0):\n",
    "        logger.info(\"============ Initialized logger ============\")\n",
    "        if (logger_verbosity > 1):\n",
    "            logger.info(pprint.pformat(OmegaConf.to_container(cfg), compact=True).strip(\"{}\"))\n",
    "        logger.info(\"The experiment is stored in %s\\n\" % exp_dir)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa65df8-6387-45bc-a923-e3639c9c927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = build_logger(cfg, logger_path, exp_dir, device, local_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5b3a0-7ce0-4b87-b8c0-709823a90697",
   "metadata": {},
   "source": [
    "## Changing things to get DOFA to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25791437-3b6d-47a6-8c9e-d5345ad1b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = (\"/explore/nobackup/projects/ilab/data/\"\n",
    "                 \"foundation_model_comparison/landsat_nlcd/Landsat_NLCD_50_agg9\")\n",
    "cfg[\"dataset\"][\"root_path\"] = test_data_dir\n",
    "cfg.train = False\n",
    "\n",
    "# ds_cfg_path = \"/explore/nobackup/people/ajkerr1/EO_FM/Testing_NBs/ilab-pangaea-bench/configs/dataset/landsatnlcd.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39923dc0-e800-4371-aef2-bfbf1f5eda27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with initialize(config_path=\"ilab-pangaea-bench/configs/dataset\", version_base=None):\n",
    "#     ds_cfg = compose(config_name=\"landsatnlcd\")\n",
    "\n",
    "# print(\"Dataset cfg loaded successfully!\")\n",
    "\n",
    "# cfg.dataset = ds_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd990ec0-523d-41fd-bfb6-57e6e317dc8f",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56016791-6b01-4e89-b436-da17479add85",
   "metadata": {},
   "source": [
    "### Initialize encoder/decoder before loading checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c080ff50-d9fc-46fa-af56-f0f99d71227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(cfg, logger):\n",
    "    encoder: Encoder = instantiate(cfg.encoder)\n",
    "    encoder.load_encoder_weights(logger)\n",
    "    logger.info(f\"Built {encoder.model_name}, using weights from: {cfg.dataset.download_url}\")\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(cfg, encoder, device, logger):\n",
    "    decoder: Decoder = instantiate(\n",
    "        cfg.decoder,\n",
    "        encoder=encoder,\n",
    "    )\n",
    "    decoder.to(device)\n",
    "    decoder_name = cfg.decoder._target_.split(\".\")[-1]\n",
    "    logger.info(f\"Built {decoder_name} decoder.\")\n",
    "    \n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db8e70-11ba-43aa-9cdd-c2f86628a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model operations in Pangaea require a logger\n",
    "encoder = build_encoder(cfg, logger)\n",
    "# Pangaea wraps encoder and decoder into one Decoder type\n",
    "encoder_decoder = build_decoder(cfg, encoder, device, logger)\n",
    "\n",
    "# Final model is built using distributed GPU resources if we have more than 1 GPU\n",
    "if (world_size > 1):\n",
    "    model = DistributedDataParallel(\n",
    "        encoder_decoder,\n",
    "        device_ids=[local_rank],\n",
    "        output_device=local_rank,\n",
    "        find_unused_parameters=cfg.finetune,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1dbca-f87e-4f60-b55e-728694902eba",
   "metadata": {},
   "source": [
    "### Load model checkpoint from path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f8add-b848-47a6-b0cb-aef9e9dbd906",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_apply_ckpt(ckpt_dir, device, encoder_decoder, logger, logger_verbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eebeff-647b-4b35-b430-b908c6aba3d4",
   "metadata": {},
   "source": [
    "## Load test data, run through model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c81bb-d2ce-4f84-ad44-5e65a2575c2e",
   "metadata": {},
   "source": [
    "### Get Dataloader\n",
    "From our config file, we can build a dataset which is then served in batches by the PyTorch DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9730e-4b87-47c8-88e3-e56dd02db76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(cfg, encoder, logger):\n",
    "    # Preprocessor is required by dataset class\n",
    "    test_preprocessor = instantiate(\n",
    "        cfg.preprocessing.test,\n",
    "        dataset_cfg=cfg.dataset,\n",
    "        encoder_cfg=cfg.encoder,\n",
    "        _recursive_=False,\n",
    "    )\n",
    "\n",
    "    # Create dataset\n",
    "    raw_test_dataset = instantiate(cfg.dataset, split=\"test\")\n",
    "    test_dataset = GeoFMDataset(raw_test_dataset, test_preprocessor)\n",
    "\n",
    "    # Create batches by modality using collate function\n",
    "    modalities = list(encoder.input_bands.keys())\n",
    "    collate_fn = get_collate_fn(modalities)\n",
    "\n",
    "    # Dataloader from dataset\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,  # Change this to a larger size if desired\n",
    "        num_workers=4,  # Change this to a larger number if desired\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    if (logger_verbosity > 1):\n",
    "        logger.info(f\"Built dataloader from dataset: {cfg.dataset.dataset_name}\")\n",
    "        logger.info(f\"Dataset gathered files from: {cfg.dataset.root_path}\")\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb266c-66cb-4d0f-a87e-0171eba443b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_dataloader(cfg, encoder, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba74c9-c54c-4df7-af8c-1887c40fc2c4",
   "metadata": {},
   "source": [
    "### Perform forward pass of model on test dataset\n",
    "Using the test dataloader, we can get model predictions on test inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95048d1a-6b4c-4d9b-9c15-6f2dd5a086a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info(\"Beginning test loop...\")\n",
    "test_dict = eval_loop(cfg, model, device, test_loader)\n",
    "logger.info(\"Testing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9283f0-f8d0-4af8-9196-6ad95a16b9c4",
   "metadata": {},
   "source": [
    "## Log metrics and visualize model performance on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d2e06-2a81-4fed-a229-7c6cece1845f",
   "metadata": {},
   "source": [
    "### Retrieve and log test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd8859c-27f5-473a-ae1c-167a7af88936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS\n",
    "\n",
    "# metric = test_dict[\"metric\"]\n",
    "# metric_value = metric[\"value\"]\n",
    "# torch.distributed.all_reduce(metric_value, op=torch.distributed.ReduceOp.SUM)\n",
    "# metric_value = metric_value / len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6745765-bd62-4860-80a2-7502b370b815",
   "metadata": {},
   "source": [
    "### Plot targets vs predictions heatmap\n",
    "This plots the first 5 targets and predictions alongside one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7aa30f-8421-4479-8896-50c44a066275",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Creating heatmap and saving to png...\")\n",
    "\n",
    "plot_results_heatmap(\n",
    "    targets=test_dict[\"targets\"], \n",
    "    preds=test_dict[\"preds\"], \n",
    "    save_dir=working_dir, \n",
    "    png_prefix=heatmap_plot_filename, \n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abec099-1704-44e4-9d56-b1388b47f6c9",
   "metadata": {},
   "source": [
    "### Create scatter plot\n",
    "This plot visualizes all prediction and target data points based on their closeness. The closer they are to the middle, the more similar they are (and the better the model is performing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd5146-2197-47e1-b528-936a5f66bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Creating scatter plot and saving to png...\")\n",
    "\n",
    "fig, val_df = plot_results_scatter(\n",
    "    targets=test_dict[\"targets\"], \n",
    "    predictions=test_dict[\"preds\"],\n",
    "    save_dir=working_dir,\n",
    "    png_prefix=scatter_plot_filename\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pangaea-bench]",
   "language": "python",
   "name": "conda-env-.conda-pangaea-bench-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
