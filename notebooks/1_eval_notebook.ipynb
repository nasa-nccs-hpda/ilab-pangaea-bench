{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d5bc6d-2166-464e-9614-b4d4dd93e214",
   "metadata": {},
   "source": [
    "# PANGAEA Model Testing Notebook\n",
    "\n",
    "Use this notebook to evaluate a Pangaea model. To modify the behavior of this notebook, you can modify the corresponding .yaml file (found under ilab-pangaea-bench/configs), as well as the cells of the notebook. See the \"global variables\" section for some easily editable variables. \n",
    "\n",
    "## Building the environment\n",
    "\n",
    "1) Find the `environment.yml` file in the repo, and executing the command: `conda env create -f environment.yml`. Make sure you are in the ilab-pangaea-repo directory that you've cloned!\n",
    "2) In the jupyterhub session, click on the top right area that says `Python [...]`, and select `conda env: conda-pangaea-bench`.\n",
    "3) You can now run the notebook as needed!\n",
    "\n",
    "## Before you run\n",
    "This notebook is designed to be run on a model that was trained using this repo, either using the training notebook or the CLI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f9727-e23f-4da7-9b4f-21b3c491a17a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import python packages, create and configure local directories, configure GPU acceleration, build logger, and set some global variables. \n",
    "\n",
    "**Note: if you want to change the functionality of this notebook, the Global Variables subsection is a good place to start.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea70f15-7d62-4a9d-8bdf-e2c6d04d6b3c",
   "metadata": {},
   "source": [
    "### Imports and clone repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6c16f6-c33e-40ca-8876-3502d8a3434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from hydra.utils import instantiate\n",
    "from hydra import initialize, compose\n",
    "from hydra import initialize_config_dir\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torchmetrics.classification import JaccardIndex\n",
    "\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import pandas as pd\n",
    "import sys\n",
    "import subprocess\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58b74598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'ilab-pangaea-bench'...\n",
      "Updating files: 100% (257/257), done.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angaea (/panfs/ccds02/nobackup/people/ajkerr1/.conda/envs/pangaea-bench/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angaea (/panfs/ccds02/nobackup/people/ajkerr1/.conda/envs/pangaea-bench/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  DEPRECATION: Legacy editable install of pangaea==1.0.0 from file:///panfs/ccds02/nobackup/people/ajkerr1/EO_FM/ilab-pangaea-bench/notebooks/ilab-pangaea-bench (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angaea (/panfs/ccds02/nobackup/people/ajkerr1/.conda/envs/pangaea-bench/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "repo_name = \"ilab-pangaea-bench\"\n",
    "if not os.path.exists(repo_name):\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/nasa-nccs-hpda/ilab-pangaea-bench.git\"], \n",
    "                   check=True, stdout=subprocess.DEVNULL)\n",
    "else:\n",
    "    subprocess.run([\"git\", \"-C\", repo_name, \"pull\"], check=True, stdout=subprocess.DEVNULL)\n",
    "\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \"./ilab-pangaea-bench\"], \n",
    "               check=True, stdout=subprocess.DEVNULL)\n",
    "sys.path.append(\"ilab-pangaea-bench\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "434ad3ea-9025-4e3d-9bdd-ff1e58550825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangaea.decoders.base import Decoder\n",
    "from pangaea.encoders.base import Encoder\n",
    "from pangaea.utils.logger import init_logger\n",
    "from pangaea.datasets.base import GeoFMDataset\n",
    "from pangaea.utils.collate_fn import get_collate_fn\n",
    "from pangaea.utils.eval_utils import (config_cuda, load_apply_ckpt, test_loop,\n",
    "                                      plot_results_heatmap, plot_results_scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25436b46-fdf8-489b-99d9-82729fe06804",
   "metadata": {},
   "source": [
    "### Create and configure directories\n",
    "These dictate where our outputs (logs, plots, etc) will be directed. A folder with the current date and time will be created.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55fe7d78-6b06-4b11-aa10-3b7a0e13420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_experiment_dirs(datetime_str, base_dir=\".\"):\n",
    "    exp_dir = Path(base_dir) / datetime_str\n",
    "    exp_dir.mkdir(exist_ok=True)\n",
    "    logger_path = exp_dir / \"test.log\"\n",
    "\n",
    "    return exp_dir, logger_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "638a676f-dae5-4cc0-8472-5b139b1019c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_str = datetime.datetime.now().strftime(\"%Y-%m-%d-%H:%M\")\n",
    "exp_dir, logger_path = make_experiment_dirs(datetime_str, \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02af3c5-f417-497a-bcc4-c9759f402a62",
   "metadata": {},
   "source": [
    "### Global Variables\n",
    "These will affect the rest of the notebook, change them for your individual task. For example, if you wish to create your own .yaml file to run this notebook, change the `config_name` variable below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "852b1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to create the working directory for this notebook\n",
    "working_dir = exp_dir  # Default is to use exp_dir for everything\n",
    "\n",
    "# Plotting path information\n",
    "heatmap_plot_filename = f\"heatmap\"\n",
    "scatter_plot_filename = f\"scatter\"\n",
    "\n",
    "# How much info the logger will display; 0 means no logging, 1 means minimal logging, 2 means extra logging detail\n",
    "logger_verbosity = 0\n",
    "\n",
    "# This creates a directory where we will load our trained model checkpoint\n",
    "ckpt_path = \"/explore/nobackup/people/mfrost2/lscratch/EO_FM/training_dir/\"\n",
    "ckpt_dir = Path(ckpt_path, \"20250822_151213_a5bd3f_dofa_landsat_seg_upernet_landsatnlcd_7band\")\n",
    "\n",
    "# This can be left as the empty string, \"\", if your test data is in the same directory as training data\n",
    "# Otherwise, this notebook will try to evaluate using the same data used to train the model checkpoint\n",
    "test_data_dir = (\"/explore/nobackup/projects/ilab/data/\"\n",
    "                 \"foundation_model_comparison/landsat_nlcd/Landsat_NLCD_50_agg9\")\n",
    "\n",
    "# Where we will load our hydra config from\n",
    "config_path = str(ckpt_dir / \"configs\" / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d754db4-1c17-48ac-bd22-d8433b07b1bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Configure Hydra\n",
    "This allows us to run a test using the .yaml framework from Pangaea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22e4babb-7454-41a8-bab6-893952008040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Init Hydra from config\n",
    "with initialize_config_dir(config_dir=config_path, version_base=None):\n",
    "    cfg = OmegaConf.load(config_path)\n",
    "\n",
    "print(\"Config loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd3349-a445-4fc4-bba4-b181d063515a",
   "metadata": {},
   "source": [
    "### Configure CUDA for GPU acceleration\n",
    "We need this to run our notebook on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a56c934e-a9f9-4a11-a973-2cb87a3b387d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single GPU training detected, skipping distributed init.\n"
     ]
    }
   ],
   "source": [
    "device, local_rank, world_size = config_cuda(cfg, backend=\"nccl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e6893a-d93e-439d-92df-8a4baee39d5d",
   "metadata": {},
   "source": [
    "### Build logger\n",
    "\n",
    "This provides some debugging information on various processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01aac4c7-b86c-4024-9022-a28e9f03daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logger(cfg, logger_path, exp_dir, device, rank=local_rank):\n",
    "    logger = init_logger(logger_path, rank=rank)\n",
    "    if (logger_verbosity > 0):\n",
    "        logger.info(\"============ Initialized logger ============\")\n",
    "        if (logger_verbosity > 1):\n",
    "            logger.info(pprint.pformat(OmegaConf.to_container(cfg), compact=True).strip(\"{}\"))\n",
    "        logger.info(\"The experiment is stored in %s\\n\" % exp_dir)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffa65df8-6387-45bc-a923-e3639c9c927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = build_logger(cfg, logger_path, exp_dir, device, local_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5b3a0-7ce0-4b87-b8c0-709823a90697",
   "metadata": {},
   "source": [
    "### Editing config to use test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25791437-3b6d-47a6-8c9e-d5345ad1b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg[\"dataset\"][\"root_path\"] = test_data_dir\n",
    "cfg.train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd990ec0-523d-41fd-bfb6-57e6e317dc8f",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56016791-6b01-4e89-b436-da17479add85",
   "metadata": {},
   "source": [
    "### Initialize encoder/decoder before loading checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c080ff50-d9fc-46fa-af56-f0f99d71227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(cfg, logger):\n",
    "    encoder: Encoder = instantiate(cfg.encoder)\n",
    "    encoder.load_encoder_weights(logger)\n",
    "    logger.info(f\"Built {encoder.model_name}, using weights from: {cfg.dataset.download_url}\")\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(cfg, encoder, device, logger):\n",
    "    decoder: Decoder = instantiate(\n",
    "        cfg.decoder,\n",
    "        encoder=encoder,\n",
    "    )\n",
    "    decoder.to(device)\n",
    "    decoder_name = cfg.decoder._target_.split(\".\")[-1]\n",
    "    logger.info(f\"Built {decoder_name} decoder.\")\n",
    "\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49db8e70-11ba-43aa-9cdd-c2f86628a470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading ./pretrained_models/DOFA_ViT_base_e100.pth: 100%|█████████▉| 427M/427M [00:09<00:00, 49.6Mb/s]   \n",
      "INFO - 09/04/25 10:18:16 - 0:00:17 - Built dofa_encoder, using weights from: None\n",
      "INFO - 09/04/25 10:18:16 - 0:00:17 - Built SegUPerNet decoder.\n"
     ]
    }
   ],
   "source": [
    "# Model operations in Pangaea require a logger\n",
    "encoder = build_encoder(cfg, logger)\n",
    "# Pangaea wraps encoder and decoder into one Decoder type\n",
    "encoder_decoder = build_decoder(cfg, encoder, device, logger)\n",
    "\n",
    "# Final model is built using distributed GPU resources if we have more than 1 GPU\n",
    "if (world_size > 1):\n",
    "    model = DistributedDataParallel(\n",
    "        encoder_decoder,\n",
    "        device_ids=[local_rank],\n",
    "        output_device=local_rank,\n",
    "        find_unused_parameters=cfg.finetune,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1dbca-f87e-4f60-b55e-728694902eba",
   "metadata": {},
   "source": [
    "### Load model checkpoint from path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "045f8add-b848-47a6-b0cb-aef9e9dbd906",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_apply_ckpt(ckpt_dir, device, encoder_decoder, logger, logger_verbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eebeff-647b-4b35-b430-b908c6aba3d4",
   "metadata": {},
   "source": [
    "## Load test data, run through model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c81bb-d2ce-4f84-ad44-5e65a2575c2e",
   "metadata": {},
   "source": [
    "### Get Dataloader\n",
    "From our config file, we can build a dataset which is then served in batches by the PyTorch DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60c9730e-4b87-47c8-88e3-e56dd02db76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(cfg, encoder, logger):\n",
    "    # Preprocessor is required by dataset class\n",
    "    test_preprocessor = instantiate(\n",
    "        cfg.preprocessing.test,\n",
    "        dataset_cfg=cfg.dataset,\n",
    "        encoder_cfg=cfg.encoder,\n",
    "        _recursive_=False,\n",
    "    )\n",
    "\n",
    "    # Create dataset\n",
    "    raw_test_dataset = instantiate(cfg.dataset, split=\"test\")\n",
    "    test_dataset = GeoFMDataset(raw_test_dataset, test_preprocessor)\n",
    "\n",
    "    # Create batches by modality using collate function\n",
    "    modalities = list(encoder.input_bands.keys())\n",
    "    collate_fn = get_collate_fn(modalities)\n",
    "\n",
    "    # Dataloader from dataset\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,  # Change this to a larger size if desired\n",
    "        num_workers=4,  # Change this to a larger number if desired\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    if (logger_verbosity > 1):\n",
    "        logger.info(f\"Built dataloader from dataset: {cfg.dataset.dataset_name}\")\n",
    "        logger.info(f\"Dataset gathered files from: {cfg.dataset.root_path}\")\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afdb266c-66cb-4d0f-a87e-0171eba443b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 paired image-label files in /explore/nobackup/projects/ilab/data/foundation_model_comparison/landsat_nlcd/Landsat_NLCD_50_agg9/images\n"
     ]
    }
   ],
   "source": [
    "test_loader = get_dataloader(cfg, encoder, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba74c9-c54c-4df7-af8c-1887c40fc2c4",
   "metadata": {},
   "source": [
    "### Perform forward pass of model on test dataset\n",
    "Using the test dataloader, we can get model predictions on test inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95048d1a-6b4c-4d9b-9c15-6f2dd5a086a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 09/04/25 10:18:19 - 0:00:20 - Beginning test loop...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loop:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds, targets devices: (device(type='cuda', index=0), device(type='cuda', index=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loop: 100%|██████████| 2/2 [00:22<00:00, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds, targets devices: (device(type='cuda', index=0), device(type='cuda', index=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Default process group has not been initialized, please make sure to call init_process_group.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBeginning test loop...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m test_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtest_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/panfs/ccds02/nobackup/people/ajkerr1/EO_FM/ilab-pangaea-bench/notebooks/ilab-pangaea-bench/pangaea/utils/eval_utils.py:275\u001b[0m, in \u001b[0;36mtest_loop\u001b[0;34m(cfg, model, device, test_loader, logger)\u001b[0m\n\u001b[1;32m    272\u001b[0m     metric_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(metric_value, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Perform all_reduce operation\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReduceOp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSUM\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# Average the metric\u001b[39;00m\n\u001b[1;32m    280\u001b[0m metric_value \u001b[38;5;241m=\u001b[39m metric_value \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_loader)\n",
      "File \u001b[0;32m~/.conda/envs/pangaea-bench/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:83\u001b[0m, in \u001b[0;36m_exception_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     85\u001b[0m         msg_dict \u001b[38;5;241m=\u001b[39m _get_msg_dict(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/pangaea-bench/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:2490\u001b[0m, in \u001b[0;36mall_reduce\u001b[0;34m(tensor, op, group, async_op)\u001b[0m\n\u001b[1;32m   2488\u001b[0m opts\u001b[38;5;241m.\u001b[39mreduceOp \u001b[38;5;241m=\u001b[39m op\n\u001b[1;32m   2489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2490\u001b[0m     group \u001b[38;5;241m=\u001b[39m \u001b[43m_get_default_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m _world\u001b[38;5;241m.\u001b[39mpg_coalesce_state\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   2493\u001b[0m     \u001b[38;5;66;03m# We are in coalescing context, do not issue single operation, just append a collective representation\u001b[39;00m\n\u001b[1;32m   2494\u001b[0m     coll \u001b[38;5;241m=\u001b[39m _CollOp(all_reduce, tensor, \u001b[38;5;28;01mNone\u001b[39;00m, op, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/pangaea-bench/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:1150\u001b[0m, in \u001b[0;36m_get_default_group\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the default process group created by init_process_group.\"\"\"\u001b[39;00m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_initialized():\n\u001b[0;32m-> 1150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault process group has not been initialized, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease make sure to call init_process_group.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1153\u001b[0m     )\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m not_none(GroupMember\u001b[38;5;241m.\u001b[39mWORLD)\n",
      "\u001b[0;31mValueError\u001b[0m: Default process group has not been initialized, please make sure to call init_process_group."
     ]
    }
   ],
   "source": [
    "logger.info(\"Beginning test loop...\")\n",
    "test_dict = test_loop(cfg, model, device, test_loader, logger)\n",
    "logger.info(\"Testing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9283f0-f8d0-4af8-9196-6ad95a16b9c4",
   "metadata": {},
   "source": [
    "## Visualize model performance on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6745765-bd62-4860-80a2-7502b370b815",
   "metadata": {},
   "source": [
    "### Plot targets vs predictions heatmap\n",
    "This plots the first 5 targets and predictions alongside one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7aa30f-8421-4479-8896-50c44a066275",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Creating heatmap and saving to png...\")\n",
    "\n",
    "plot_results_heatmap(\n",
    "    targets=test_dict[\"targets\"],\n",
    "    preds=test_dict[\"preds\"],\n",
    "    save_dir=working_dir,\n",
    "    png_prefix=heatmap_plot_filename,\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abec099-1704-44e4-9d56-b1388b47f6c9",
   "metadata": {},
   "source": [
    "### Create scatter plot\n",
    "This plot visualizes all prediction and target data points based on their closeness. The closer they are to the middle, the more similar they are (and the better the model is performing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd5146-2197-47e1-b528-936a5f66bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Creating scatter plot and saving to png...\")\n",
    "\n",
    "fig, val_df = plot_results_scatter(\n",
    "    targets=test_dict[\"targets\"],\n",
    "    predictions=test_dict[\"preds\"],\n",
    "    save_dir=working_dir,\n",
    "    png_prefix=scatter_plot_filename\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pangaea-bench]",
   "language": "python",
   "name": "conda-env-.conda-pangaea-bench-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
